{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-24 17:09:07.225526: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-24 17:09:07.225544: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "abidata = '/root/digi_twin_summer_wireless_dataset/data_split_clean'\n",
    "abidata2 = '/root/digi_twin_summer_wireless_dataset/dataset-2'\n",
    "kpi_ = '/*kpis.txt'\n",
    "tfc_ = '/*traffic.txt'\n",
    "traincon = '/train'\n",
    "valcon = '/validate'\n",
    "testcon = '/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainkpis = glob.glob(abidata+traincon+kpi_)\n",
    "trainkpis.sort()\n",
    "traintraffics = glob.glob(abidata+traincon+tfc_)\n",
    "traintraffics.sort()\n",
    "\n",
    "valkpis = glob.glob(abidata+valcon+kpi_)\n",
    "valkpis.sort()\n",
    "valtraffics = glob.glob(abidata+valcon+tfc_)\n",
    "valtraffics.sort()\n",
    "\n",
    "testkpis = glob.glob(abidata+testcon+kpi_)\n",
    "testkpis.sort()\n",
    "testtraffics = glob.glob(abidata+testcon+tfc_)\n",
    "testtraffics.sort()\n",
    "\n",
    "test2kpis = glob.glob(abidata2+testcon+kpi_)\n",
    "test2kpis.sort()\n",
    "test2traffics = glob.glob(abidata2+testcon+tfc_)\n",
    "test2traffics.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JoseDataGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, filenames, hparams):\n",
    "        self.hparams = hparams\n",
    "        \n",
    "        kpis, tris = filenames\n",
    "        \n",
    "        \n",
    "        kpiframe = pd.read_csv(kpis[0], header=None)\n",
    "        # for k in kpis[1:]:\n",
    "        #     kpiframe = pd.concat([kpiframe, pd.read_csv(k, header=None)])\n",
    "        self.kpiframe = kpiframe.reset_index(drop=True)\n",
    "\n",
    "        self.n = kpiframe.shape[0]\n",
    "        triframe = pd.read_csv(tris[0], header=None)\n",
    "        # for k in tris[1:]:\n",
    "        #     triframe = pd.concat([triframe, pd.read_csv(k, header=None)])\n",
    "        self.triframe = triframe.reset_index(drop=True)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self, index=None):\n",
    "        \n",
    "        a = self.triframe.loc[index]\n",
    "        b = self.kpiframe.loc[index]\n",
    "        #links and paths\n",
    "        f_n_links = 42\n",
    "        f_n_nodes = 14\n",
    "        f_n_paths = 10\n",
    "\n",
    "        f_degrees = [1.0]*14\n",
    "        \n",
    "        f_capacities = [1.0]*42\n",
    "\n",
    "        traffic_in = [float(a[i]) for i in range(0, len(a), 2)]\n",
    "        traffic_ot = [float(a[i]) for i in range(1, len(a), 2)]\n",
    "        f_traffic = [traffic_in, traffic_ot]\n",
    "\n",
    "        f_links_to_paths = [0, 5, 5, 14, 34, 11, 18, 6, 25, 20, 38, 33, 36, 40, 28, 30, 16, 19]\n",
    "\n",
    "        f_link_state_dim = 32\n",
    "\n",
    "        f_nodes_to_paths = [0, 1, 1, 7, 10, 2, 5, 3, 6, 4, 9, 10, 9, 11, 12, 13, 5, 4]\n",
    "\n",
    "        f_node_state_dim = 32\n",
    "\n",
    "        f_links_to_nodes = [0, 0, 0, 1, 1, 1, 3, 3, 3, 2, 2, 2, 7, 7, 7, 5, 5, 5, 5, 4, 4, 4, 8, 8, 8, 6, 6, 12, 12, 12, 13, 13, 10, 10, 10, 10, 9, 9, 9, 11, 11, 11]\n",
    "        # len 42 ^\n",
    "        \n",
    "        f_nodes_to_links = [0, 1, 1, 2, 11, 3, 4, 5, 6, 7, 8, 9, 10, 11, 8, 4, 7, 12]\n",
    "\n",
    "        f_paths_to_x = [0, 0, 1, 1, 1, 2, 2, 3, 4, 4, 5, 6, 6, 7, 8, 9, 9, 9]\n",
    "        f_sequences_paths_x = [0, 1, 0, 1, 2, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 2]\n",
    "\n",
    "        l_delay = [float(b[i]) for i in range(2, len(b), 3)]\n",
    "\n",
    "        # features = {\n",
    "        #     'n_nodes': tf.Variable(tf.constant(f_n_nodes)), #0\n",
    "        #     'n_links': tf.Variable(tf.constant(f_n_links)), #1\n",
    "        #     'n_paths': tf.Variable(tf.constant(f_n_paths)), #2\n",
    "        #     'node_init': tf.Variable(tf.constant(f_degrees)), #3\n",
    "        #     'link_init': tf.Variable(tf.constant(f_capacities)), #4\n",
    "        #     'path_init': tf.Variable(tf.constant(f_traffic)), #5\n",
    "        #     'nodes_to_paths': tf.Variable(tf.constant(f_nodes_to_paths)), #6\n",
    "        #     'links_to_paths': tf.Variable(tf.constant(f_links_to_paths)), #7\n",
    "        #     'links_to_nodes': tf.Variable(tf.constant(f_links_to_nodes)), #8\n",
    "        #     'paths_to_x': tf.Variable(tf.constant(f_paths_to_x)), #9\n",
    "        #     'sequences_paths_x': tf.Variable(tf.constant(f_sequences_paths_x)), #10\n",
    "        #     'node_lapacian': tf.Variable(tf.constant(lap, dtype=np.float32)) #11\n",
    "        # }\n",
    "        features = [\n",
    "            tf.Variable(tf.constant(f_degrees)), #0\n",
    "            tf.Variable(tf.constant(f_capacities)), #1\n",
    "            tf.Variable(tf.constant(f_traffic)), #2\n",
    "            tf.Variable(tf.constant(f_n_nodes)), #3\n",
    "            tf.Variable(tf.constant(f_n_links)), #4\n",
    "            tf.Variable(tf.constant(f_n_paths)), #5\n",
    "            tf.Variable(tf.constant(f_nodes_to_paths)), #6\n",
    "            tf.Variable(tf.constant(f_links_to_paths)), #7\n",
    "            tf.Variable(tf.constant(f_links_to_nodes)), #8\n",
    "            tf.Variable(tf.constant(f_paths_to_x)), #9\n",
    "            tf.Variable(tf.constant(f_sequences_paths_x)), #10\n",
    "            tf.Variable(tf.constant(f_nodes_to_links)), #11\n",
    "\n",
    "        ]\n",
    "\n",
    "        labels = [\n",
    "            tf.Variable(tf.constant(l_delay)), #0\n",
    "        ]\n",
    "\n",
    "        #return sample\n",
    "        return [features, labels]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n #// self.hparams['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'node_count':14,\n",
    "    'link_state_dim':32, \n",
    "    #[4, 8, 16, 32, 64]\n",
    "    'path_state_dim':32,\n",
    "    #[2, 4, 8, 16, 32, 64]\n",
    "    'node_state_dim':32,\n",
    "    #[2, 4, 8, 16, 32, 64]\n",
    "    'T':8,\n",
    "    'readout_units':8,\n",
    "    'learning_rate':0.001,\n",
    "    #[.001, .01, .05]\n",
    "    'batch_size':10,\n",
    "    #[8, 16, 32, 64]\n",
    "    'dropout_rate':0.5,\n",
    "    #[.5] leave\n",
    "    'l2':0.1,\n",
    "    #regulirization constants\n",
    "    #[.05, .1, .2]\n",
    "    'l2_2':0.01,\n",
    "    #[.005, .01, .02]\n",
    "    'learn_embedding':True, # If false, only the readout is trained\n",
    "    'readout_layers':2, # number of hidden layers in readout model\n",
    "    #[2, 3, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "traingen = JoseDataGen((trainkpis, traintraffics), hparams=hparams)\n",
    "\n",
    "valgen = JoseDataGen((valkpis, valtraffics), hparams=hparams)\n",
    "\n",
    "testgen = JoseDataGen((testkpis, testtraffics), hparams=hparams)\n",
    "\n",
    "test2gen = JoseDataGen((test2kpis, test2traffics), hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JoseNet1(tf.keras.Model):\n",
    "    def __init__(self,hparams, output_units=1, final_activation=None):\n",
    "        super(JoseNet1, self).__init__()\n",
    "\n",
    "        self.hparams = hparams\n",
    "        self.output_units = output_units\n",
    "        self.final_activation = final_activation\n",
    "        \n",
    "\n",
    "        \n",
    "    def build(self, input_shape=None):\n",
    "        del input_shape\n",
    "\n",
    "        #state updaters\n",
    "        self.edge_update = tf.keras.layers.GRUCell(hparams['link_state_dim'], name=\"edge_update\")\n",
    "        self.path_update = tf.keras.layers.GRUCell(hparams['path_state_dim'], name=\"path_update\")\n",
    "        self.node_update = tf.keras.layers.GRUCell(hparams['node_state_dim'], name=\"node_update\")\n",
    "\n",
    "        #readout-final\n",
    "        \n",
    "        self.readout = tf.keras.models.Sequential(name='readout')\n",
    "\n",
    "        for i in range(hparams['readout_layers']):\n",
    "            self.readout.add(tf.keras.layers.Dense(hparams['readout_units'], \n",
    "                    activation=tf.nn.selu,\n",
    "                    kernel_regularizer=tf.keras.regularizers.L2(hparams['l2'])))\n",
    "\n",
    "            self.readout.add(tf.keras.layers.Dropout(rate=hparams['dropout_rate']))\n",
    "\n",
    "        self.final = tf.keras.layers.Dense(self.output_units, \n",
    "                kernel_regularizer=tf.keras.regularizers.L2(hparams['l2_2']),\n",
    "                activation = self.final_activation )\n",
    "        \n",
    "        self.edge_update.build(tf.TensorShape([None,hparams['path_state_dim']+hparams['node_state_dim']]))\n",
    "        self.node_update.build(tf.TensorShape([None,hparams['path_state_dim']+hparams['link_state_dim']]))\n",
    "        self.path_update.build(tf.TensorShape([None,hparams['link_state_dim']+hparams['node_state_dim']]))\n",
    "        \n",
    "        self.readout.build(input_shape = [None,hparams['path_state_dim']])\n",
    "        self.final.build(input_shape = [None,hparams['path_state_dim'] + hparams['readout_units'] ])\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        #call == v ==\n",
    "        f_ = inputs\n",
    "\n",
    "        #state init\n",
    "        # shape = tf.stack([f_['n_links'],hparams['link_state_dim']-1], axis=0)\n",
    "        shape = tf.stack([f_[4],hparams['link_state_dim']-1], axis=0)\n",
    "        link_state = tf.concat([\n",
    "            # tf.expand_dims(f_['link_init'],axis=1),\n",
    "            tf.expand_dims(f_[1],axis=1),\n",
    "            tf.zeros(shape)\n",
    "        ], axis=1)\n",
    "\n",
    "        # shape = tf.stack([f_['n_nodes'],hparams['node_state_dim']-1], axis=0)\n",
    "        shape = tf.stack([f_[3],hparams['node_state_dim']-1], axis=0)\n",
    "        node_state = tf.concat([\n",
    "            # tf.expand_dims(f_['node_init'],axis=1),\n",
    "            tf.expand_dims(f_[0],axis=1),\n",
    "            tf.zeros(shape)\n",
    "        ], axis=1)\n",
    "\n",
    "        # shape = tf.stack([f_['n_paths'],hparams['path_state_dim']-1], axis=0)\n",
    "        shape = tf.stack([f_[5],hparams['path_state_dim']-2], axis=0)\n",
    "        path_state = tf.concat([\n",
    "            tf.expand_dims(f_[2][0],axis=1),\n",
    "            tf.expand_dims(f_[2][1],axis=1),\n",
    "            # tf.expand_dims(f_['path_init'],axis=1),\n",
    "            # tf.expand_dims(f_[5],axis=1),\n",
    "            tf.zeros(shape)\n",
    "        ], axis=1)\n",
    "\n",
    "        #pull for both\n",
    "        # paths = f_['paths_to_x']\n",
    "        paths = f_[9]\n",
    "        # seqs=  f_['sequences_paths_x']\n",
    "        seqs=  f_[10]\n",
    "        # n_paths = f_['n_paths']\n",
    "        n_paths = f_[5]\n",
    "        \n",
    "        for _ in range(hparams['T']):\n",
    "        #stuff for both\n",
    "            ids=tf.stack([paths, seqs], axis=1)\n",
    "            max_len = tf.reduce_max(seqs)+1\n",
    "            lens = tf.math.segment_sum(data=tf.ones_like(paths),\n",
    "                                    segment_ids=paths)\n",
    "\n",
    "            #link stuff\n",
    "            # h_ = tf.gather(link_state,f_['links_to_paths'])\n",
    "            h_ = tf.gather(link_state,f_[7])\n",
    "\n",
    "            shape = tf.stack([n_paths, max_len, hparams['link_state_dim']])\n",
    "            link_inputs = tf.scatter_nd(ids, h_, shape)\n",
    "            \n",
    "            #node stuff\n",
    "            # h_ = tf.gather(link_state,f_['nodes_to_paths'])\n",
    "            h_ = tf.gather(link_state,f_[6])\n",
    "\n",
    "            shape = tf.stack([n_paths, max_len, hparams['node_state_dim']])\n",
    "            node_inputs = tf.scatter_nd(ids, h_, shape)\n",
    "            \n",
    "            x_inputs = tf.concat([link_inputs, node_inputs], axis=2)\n",
    "            \n",
    "            #updating path_state\n",
    "            outputs, path_state = tf.compat.v1.nn.dynamic_rnn(cell = self.path_update,\n",
    "                                                inputs = x_inputs,\n",
    "                                                sequence_length = lens,\n",
    "                                                initial_state = path_state,\n",
    "                                                dtype=tf.float32)\n",
    "            \n",
    "            m0 = tf.gather_nd(outputs,ids)\n",
    "\n",
    "            #link update\n",
    "\n",
    "            #fitting nodes to links\n",
    "            # m = tf.math.unsorted_segment_sum(m, f_['links_to_paths'] ,f_['n_links'])\n",
    "            m = tf.math.unsorted_segment_sum(m0, f_[7] ,f_[4])\n",
    "            # h_ = tf.gather(node_state,f_['links_to_nodes'])\n",
    "            h_ = tf.gather(node_state, f_[8])\n",
    "            print(h_.shape)\n",
    "            print(m.shape)\n",
    "            _con = tf.concat([h_, m], axis=1)\n",
    "            \n",
    "            link_state,_ = self.edge_update(_con, [link_state])\n",
    "            \n",
    "            #node update\n",
    "\n",
    "            #fitting nodes to links\n",
    "            # m = tf.math.unsorted_segment_sum(m, f_['nodes_to_paths'] ,f_['n_nodes'])\n",
    "            m = tf.math.unsorted_segment_sum(m0, f_[6] ,f_[3])\n",
    "            # print(m)\n",
    "            # h_ = tf.gather(link_state,f_['nodes_to_links'])\n",
    "            h_ = tf.gather(link_state, f_[11])\n",
    "            print(h_.shape)\n",
    "            print(m.shape)\n",
    "            _con = tf.concat([h_, m], axis=1)\n",
    "            \n",
    "            node_state,_ = self.edge_update(_con, [node_state])\n",
    "\n",
    "        #readout\n",
    "                \n",
    "        if hparams['learn_embedding']:\n",
    "            r = self.readout(path_state,training=training)\n",
    "            o = self.final(tf.concat([r,path_state], axis=1))\n",
    "            \n",
    "        else:\n",
    "            r = self.readout(tf.stop_gradient(path_state),training=training)\n",
    "            o = self.final(tf.concat([r, tf.stop_gradient(path_state)], axis=1) )\n",
    "\n",
    "        return o\n",
    "\n",
    "    def train_step(self, data):\n",
    "        features, labels = data\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(features, training=True)\n",
    "            loc  = predictions[...,0]\n",
    "            delay_prediction = loc\n",
    "            loss = tf.keras.metrics.mean_squared_error(labels[0], loc)\n",
    "\n",
    "            regularization_loss = sum(self.losses)\n",
    "            total_loss = loss + regularization_loss\n",
    "            \n",
    "        gradients = tape.gradient(total_loss, self.trainable_variables)\n",
    "        \n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        ret = {\n",
    "            'loss':loss,\n",
    "            'label/mean/delay':tf.math.reduce_mean(labels[0]),\n",
    "            'prediction/mean/delay': tf.math.reduce_mean(delay_prediction)\n",
    "            }\n",
    "        return ret\n",
    "\n",
    "    def test_step(self, data):\n",
    "        features, labels = data\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(features, training=False)\n",
    "            loc  = predictions[...,0]\n",
    "            delay_prediction = loc\n",
    "            loss = tf.keras.metrics.mean_squared_error(labels[0], loc)\n",
    "\n",
    "            regularization_loss = sum(self.losses)\n",
    "            total_loss = loss + regularization_loss\n",
    "            \n",
    "        # gradients = tape.gradient(total_loss, self.trainable_variables)\n",
    "        \n",
    "        # self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        ret = {\n",
    "            'loss':loss,\n",
    "            'label/mean/delay':tf.math.reduce_mean(labels[0]),\n",
    "            'prediction/mean/delay': tf.math.reduce_mean(delay_prediction)\n",
    "            }\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_ = JoseNet1(hparams)\n",
    "r_.build()\n",
    "r_.compile(optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42, 32)\n",
      "(42, 32)\n",
      "(18, 32)\n",
      "(14, 32)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer \"jose_net1_7\" (type JoseNet1).\n\nConcatOp : Dimension 0 in both shapes must be equal: shape[0] = [18,32] vs. shape[1] = [14,32] [Op:ConcatV2] name: concat\n\nCall arguments received by layer \"jose_net1_7\" (type JoseNet1):\n  • inputs=[\"<tf.Variable 'Variable:0' shape=(14,) dtype=float32, numpy=\\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\\n      dtype=float32)>\", \"<tf.Variable 'Variable:0' shape=(42,) dtype=float32, numpy=\\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\\n       1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>\", \"<tf.Variable 'Variable:0' shape=(2, 10) dtype=float32, numpy=\\narray([[ 1.,  1.,  1., 10.,  1.,  1.,  1., 20., 20.,  1.],\\n       [10.,  1., 20., 10.,  1., 10.,  1.,  1., 10.,  1.]], dtype=float32)>\", \"<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=14>\", \"<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=42>\", \"<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=10>\", \"<tf.Variable 'Variable:0' shape=(18,) dtype=int32, numpy=\\narray([ 0,  1,  1,  7, 10,  2,  5,  3,  6,  4,  9, 10,  9, 11, 12, 13,  5,\\n        4], dtype=int32)>\", \"<tf.Variable 'Variable:0' shape=(18,) dtype=int32, numpy=\\narray([ 0,  5,  5, 14, 34, 11, 18,  6, 25, 20, 38, 33, 36, 40, 28, 30, 16,\\n       19], dtype=int32)>\", \"<tf.Variable 'Variable:0' shape=(42,) dtype=int32, numpy=\\narray([ 0,  0,  0,  1,  1,  1,  3,  3,  3,  2,  2,  2,  7,  7,  7,  5,  5,\\n        5,  5,  4,  4,  4,  8,  8,  8,  6,  6, 12, 12, 12, 13, 13, 10, 10,\\n       10, 10,  9,  9,  9, 11, 11, 11], dtype=int32)>\", \"<tf.Variable 'Variable:0' shape=(18,) dtype=int32, numpy=array([0, 0, 1, 1, 1, 2, 2, 3, 4, 4, 5, 6, 6, 7, 8, 9, 9, 9], dtype=int32)>\", \"<tf.Variable 'Variable:0' shape=(18,) dtype=int32, numpy=array([0, 1, 0, 1, 2, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 2], dtype=int32)>\", \"<tf.Variable 'Variable:0' shape=(18,) dtype=int32, numpy=\\narray([ 0,  1,  1,  2, 11,  3,  4,  5,  6,  7,  8,  9, 10, 11,  8,  4,  7,\\n       12], dtype=int32)>\"]\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/root/code/RouteNetButBetter/JoseNet/JoseNet.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f4a6f73655466326473222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6c69646f342e6563652e726963652e656475227d7d/root/code/RouteNetButBetter/JoseNet/JoseNet.ipynb#ch0000010vscode-remote?line=0'>1</a>\u001b[0m r_(traingen\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(\u001b[39m0\u001b[39;49m)[\u001b[39m0\u001b[39;49m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;32m/root/code/RouteNetButBetter/JoseNet/JoseNet.ipynb Cell 11\u001b[0m in \u001b[0;36mJoseNet1.call\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f4a6f73655466326473222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6c69646f342e6563652e726963652e656475227d7d/root/code/RouteNetButBetter/JoseNet/JoseNet.ipynb#ch0000010vscode-remote?line=133'>134</a>\u001b[0m     \u001b[39mprint\u001b[39m(h_\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f4a6f73655466326473222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6c69646f342e6563652e726963652e656475227d7d/root/code/RouteNetButBetter/JoseNet/JoseNet.ipynb#ch0000010vscode-remote?line=134'>135</a>\u001b[0m     \u001b[39mprint\u001b[39m(m\u001b[39m.\u001b[39mshape)\n\u001b[0;32m--> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f4a6f73655466326473222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6c69646f342e6563652e726963652e656475227d7d/root/code/RouteNetButBetter/JoseNet/JoseNet.ipynb#ch0000010vscode-remote?line=135'>136</a>\u001b[0m     _con \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mconcat([h_, m], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f4a6f73655466326473222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6c69646f342e6563652e726963652e656475227d7d/root/code/RouteNetButBetter/JoseNet/JoseNet.ipynb#ch0000010vscode-remote?line=137'>138</a>\u001b[0m     node_state,_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_update(_con, [node_state])\n\u001b[1;32m    <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f4a6f73655466326473222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6c69646f342e6563652e726963652e656475227d7d/root/code/RouteNetButBetter/JoseNet/JoseNet.ipynb#ch0000010vscode-remote?line=139'>140</a>\u001b[0m \u001b[39m#readout\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer \"jose_net1_7\" (type JoseNet1).\n\nConcatOp : Dimension 0 in both shapes must be equal: shape[0] = [18,32] vs. shape[1] = [14,32] [Op:ConcatV2] name: concat\n\nCall arguments received by layer \"jose_net1_7\" (type JoseNet1):\n  • inputs=[\"<tf.Variable 'Variable:0' shape=(14,) dtype=float32, numpy=\\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\\n      dtype=float32)>\", \"<tf.Variable 'Variable:0' shape=(42,) dtype=float32, numpy=\\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\\n       1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>\", \"<tf.Variable 'Variable:0' shape=(2, 10) dtype=float32, numpy=\\narray([[ 1.,  1.,  1., 10.,  1.,  1.,  1., 20., 20.,  1.],\\n       [10.,  1., 20., 10.,  1., 10.,  1.,  1., 10.,  1.]], dtype=float32)>\", \"<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=14>\", \"<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=42>\", \"<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=10>\", \"<tf.Variable 'Variable:0' shape=(18,) dtype=int32, numpy=\\narray([ 0,  1,  1,  7, 10,  2,  5,  3,  6,  4,  9, 10,  9, 11, 12, 13,  5,\\n        4], dtype=int32)>\", \"<tf.Variable 'Variable:0' shape=(18,) dtype=int32, numpy=\\narray([ 0,  5,  5, 14, 34, 11, 18,  6, 25, 20, 38, 33, 36, 40, 28, 30, 16,\\n       19], dtype=int32)>\", \"<tf.Variable 'Variable:0' shape=(42,) dtype=int32, numpy=\\narray([ 0,  0,  0,  1,  1,  1,  3,  3,  3,  2,  2,  2,  7,  7,  7,  5,  5,\\n        5,  5,  4,  4,  4,  8,  8,  8,  6,  6, 12, 12, 12, 13, 13, 10, 10,\\n       10, 10,  9,  9,  9, 11, 11, 11], dtype=int32)>\", \"<tf.Variable 'Variable:0' shape=(18,) dtype=int32, numpy=array([0, 0, 1, 1, 1, 2, 2, 3, 4, 4, 5, 6, 6, 7, 8, 9, 9, 9], dtype=int32)>\", \"<tf.Variable 'Variable:0' shape=(18,) dtype=int32, numpy=array([0, 1, 0, 1, 2, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 2], dtype=int32)>\", \"<tf.Variable 'Variable:0' shape=(18,) dtype=int32, numpy=\\narray([ 0,  1,  1,  2, 11,  3,  4,  5,  6,  7,  8,  9, 10, 11,  8,  4,  7,\\n       12], dtype=int32)>\"]\n  • training=False"
     ]
    }
   ],
   "source": [
    "r_(traingen.__getitem__(0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
